{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Run cell only in GoogleColab",
   "id": "90627602666a6128"
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "Mrd0TKmS3CQd",
    "outputId": "44d7d961-0f27-4ff6-a784-7e4929ecbf59",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "Mrd0TKmS3CQd",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "##### Installing dependencies (run cell only in GoogleColab)",
   "metadata": {
    "id": "6RomPqxm_6mC"
   },
   "id": "6RomPqxm_6mC"
  },
  {
   "cell_type": "code",
   "source": [
    "# Install a specific version of numpy first\n",
    "!pip install numpy==1.23.5 # You might need to adjust the numpy version based on your MONAI version\n",
    "\n",
    "# Install monai and torch\n",
    "!pip install monai\n",
    "!pip install torch"
   ],
   "metadata": {
    "id": "PJzrswjD3j4L"
   },
   "id": "PJzrswjD3j4L",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb3a5df9",
   "metadata": {
    "id": "cb3a5df9"
   },
   "source": [
    "#### In this Jupyter Notebook we will display the results after training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96000eda",
   "metadata": {
    "id": "96000eda"
   },
   "source": [
    "##### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea815e7f",
   "metadata": {
    "id": "ea815e7f"
   },
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "from glob import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.amp import autocast, GradScaler\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss, TverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import Dataset, CacheDataset,DataLoader\n",
    "from monai.utils import set_determinism\n",
    "from monai.networks.utils import one_hot\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    CropForegroundd,\n",
    "    Orientationd,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "6cb9bdee",
   "metadata": {
    "id": "6cb9bdee"
   },
   "source": [
    "##### Setting the path to the working directories"
   ]
  },
  {
   "cell_type": "code",
   "id": "790dbd62",
   "metadata": {
    "id": "790dbd62",
    "outputId": "867d751f-d7c1-4a3a-84f1-62eb15a00ce8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# The input paths for the prepared nifti files\n",
    "nif_path = ['drive/MyDrive/data_set_group_nif/nif_files_testing/images',\n",
    "            'drive/MyDrive/data_set_group_nif/nif_files_testing/labels',\n",
    "            'drive/MyDrive/data_set_group_nif/nif_files_training/images',\n",
    "            'drive/MyDrive/data_set_group_nif/nif_files_training/labels',]\n",
    "\n",
    "print(nif_path[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "drive/MyDrive/data_set_group_nif/nif_files_testing/images\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "7f290f77ce837ce1"
   },
   "cell_type": "markdown",
   "source": [
    "##### Define the function for data preprocessing"
   ],
   "id": "7f290f77ce837ce1"
  },
  {
   "metadata": {
    "id": "8d8f5fc427d9fc7e"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "def preprocess_data(data_path, batch_size=8, spatial_size=(96, 96, 16)):\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    # Create the dataset\n",
    "    test_data = sorted(glob(data_path[0] + f'/*'))\n",
    "    test_labels = sorted(glob(data_path[1] + f'/*'))\n",
    "\n",
    "    train_data = sorted(glob(data_path[2] + f'/*'))\n",
    "    train_labels = sorted(glob(data_path[3] + f'/*'))\n",
    "\n",
    "    train_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in\n",
    "                   zip(train_data, train_labels)]\n",
    "    test_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_data, test_labels)]\n",
    "\n",
    "    # Transforms for the training with data augmentation\n",
    "    train_transforms = Compose(  # Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),  # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),  # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),  # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),\n",
    "            # Change the contrast of the image and gives the image pixels,\n",
    "            # values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),  # Crop foreground of the image\n",
    "            RandAffined(keys=['image', 'label'], prob=0.5, translate_range=10),  # Randomly shift the image\n",
    "            RandRotated(keys=['image', 'label'], prob=0.5, range_x=10.0),  # Randomly rotate the image\n",
    "            RandGaussianNoised(keys='image', prob=0.5),  # Add random noise to the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size),  # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]),  # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Transforms for the testing\n",
    "    test_transforms = Compose(  # Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),  # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),  # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),  # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True), # Change the contrast of the image and gives the image pixels, values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),  # Crop foreground of the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size),  # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]),  # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the datasets\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
    "\n",
    "    test_ds = CacheDataset(data=test_files, transform=test_transforms)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "id": "8d8f5fc427d9fc7e"
  },
  {
   "cell_type": "markdown",
   "id": "33a723d6",
   "metadata": {
    "id": "33a723d6"
   },
   "source": [
    "##### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "sqj2Fmmwclih"
   },
   "id": "sqj2Fmmwclih"
  },
  {
   "cell_type": "code",
   "id": "b5586891",
   "metadata": {
    "id": "b5586891",
    "outputId": "7ed7943e-b63d-4a21-cb21-98780b0fd4d2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": "data_in = preprocess_data(nif_path, batch_size=8, spatial_size=(96, 96, 16))",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "Loading dataset: 100%|██████████| 748/748 [07:02<00:00,  1.77it/s]\n",
      "Loading dataset: 100%|██████████| 240/240 [02:31<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "15b1f3a791137aae",
   "metadata": {
    "id": "15b1f3a791137aae"
   },
   "source": [
    "##### Setting the device for training"
   ]
  },
  {
   "cell_type": "code",
   "id": "4425e0a7f3020fad",
   "metadata": {
    "id": "4425e0a7f3020fad",
    "outputId": "d1072225-6cce-4a99-cd71-90d19a6ad402",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# We do the training on the GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "40ff691e13ece641",
   "metadata": {
    "id": "40ff691e13ece641"
   },
   "source": [
    "##### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8ad17af36631361",
   "metadata": {
    "id": "d8ad17af36631361"
   },
   "source": [
    "model = AttentionUnet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "156e8458c7fb1dc7",
   "metadata": {
    "id": "156e8458c7fb1dc7"
   },
   "source": [
    "##### Initialize the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a79dfc6615d0868",
   "metadata": {
    "id": "2a79dfc6615d0868"
   },
   "source": [
    "loss_function = DiceFocalLoss(to_onehot_y=True, softmax=True, lambda_focal=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5, amsgrad=True)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "id": "1506715d8d977110"
   },
   "cell_type": "markdown",
   "source": [
    "##### Define the training loop"
   ],
   "id": "1506715d8d977110"
  },
  {
   "metadata": {
    "id": "349d3416d78afc91"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 48,
   "source": [
    "def train(model, data_in, loss_function, optimizer, max_epochs, model_dir, test_interval=1,\n",
    "          device=torch.device('cuda:0')):\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train = []\n",
    "    save_loss_test = []\n",
    "    save_metric_train = []\n",
    "    save_metric_test = []\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        train_step = 0\n",
    "        train_epoch_metric = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            train_step += 1\n",
    "            volumes = batch_data[\"image\"]\n",
    "            labels = batch_data[\"label\"]\n",
    "            labels = labels != 0\n",
    "            volumes = volumes.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(volumes)\n",
    "\n",
    "            train_loss = loss_function(outputs, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_metric = dice_metric(outputs, labels)\n",
    "            train_epoch_metric += train_metric\n",
    "\n",
    "            print(\n",
    "                f\"{epoch + 1}/{max_epochs} and {train_step}/{len(train_loader)} => train_loss: {train_loss.item():.4f} and train_metric: {train_metric:.4f}\")\n",
    "\n",
    "        print('Saving training data after epoch: ' + str(epoch + 1))\n",
    "        train_epoch_loss /= train_step\n",
    "        print(f\"epoch {epoch + 1} average training loss: {train_epoch_loss:.4f}\")\n",
    "        save_loss_train.append(train_epoch_loss)\n",
    "        np.save(os.path.join(model_dir, 'train_loss.npy'), save_loss_train)\n",
    "\n",
    "        train_epoch_metric /= train_step\n",
    "        print(f\"epoch {epoch + 1} average training metric: {train_epoch_metric:.4f}\")\n",
    "        save_metric_train.append(train_epoch_metric)\n",
    "        np.save(os.path.join(model_dir, 'train_metric.npy'), save_metric_train)\n",
    "\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_epoch_loss = 0\n",
    "                test_metric = 0\n",
    "                test_step = 0\n",
    "                test_epoch_metric = 0\n",
    "\n",
    "                for test_data in test_loader:\n",
    "                    test_step += 1\n",
    "                    volumes = test_data[\"image\"]\n",
    "                    labels = test_data[\"label\"]\n",
    "                    labels = labels != 0\n",
    "                    volumes = volumes.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(volumes)\n",
    "\n",
    "                    test_loss = loss_function(outputs, labels)\n",
    "\n",
    "                    test_epoch_loss += test_loss.item()\n",
    "                    test_metric = dice_metric(outputs, labels)\n",
    "                    test_epoch_metric += test_metric\n",
    "\n",
    "                    print(\n",
    "                        f\"{epoch + 1}/{max_epochs} and {test_step}/{len(test_loader)} => test_loss: {test_loss.item():.4f} and test_metric: {test_metric:.4f}\")\n",
    "\n",
    "                print('Saving testing data after epoch: ' + str(epoch + 1))\n",
    "                test_epoch_loss /= test_step\n",
    "                print(f\"epoch {epoch + 1} average testing loss: {test_epoch_loss:.4f}\")\n",
    "                save_loss_test.append(test_epoch_loss)\n",
    "                np.save(os.path.join(model_dir, 'test_loss.npy'), save_loss_test)\n",
    "\n",
    "                test_epoch_metric /= test_step\n",
    "                print(f\"epoch {epoch + 1} average testing metric: {test_epoch_metric:.4f}\")\n",
    "                save_metric_test.append(test_epoch_metric)\n",
    "                np.save(os.path.join(model_dir, 'test_metric.npy'), save_metric_test)\n",
    "\n",
    "                if test_epoch_metric > best_metric:\n",
    "                    best_metric = test_epoch_metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_model.pth\"))\n",
    "\n",
    "                print(f\"current epoch: {epoch + 1} current test Dice coefficient: {test_epoch_metric:.4f}\"\n",
    "                      f\"\\nbest metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "\n",
    "    print(f\"train completed => best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ],
   "id": "349d3416d78afc91"
  },
  {
   "cell_type": "markdown",
   "id": "8b4ab43200d91d61",
   "metadata": {
    "id": "8b4ab43200d91d61"
   },
   "source": [
    "##### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1a67f1a5a944836",
   "metadata": {
    "id": "d1a67f1a5a944836",
    "outputId": "238e8ef7-58ac-4aa4-8bee-f5bacb84fd51",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "model_dir = 'drive/MyDrive/trained_models/post_training_AttentionUnet'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "train(model=model,\n",
    "      data_in=data_in,\n",
    "      loss_function=loss_function,\n",
    "      optimizer=optimizer,\n",
    "      max_epochs=10,\n",
    "      model_dir=model_dir,\n",
    "      test_interval=1,\n",
    "      device=device\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
