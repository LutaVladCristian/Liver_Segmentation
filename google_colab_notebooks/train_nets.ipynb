{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Run cell only in GoogleColab",
   "id": "90627602666a6128"
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "Mrd0TKmS3CQd",
    "outputId": "44d7d961-0f27-4ff6-a784-7e4929ecbf59",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "Mrd0TKmS3CQd",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "##### Installing dependencies (run cell only in GoogleColab)",
   "metadata": {
    "id": "6RomPqxm_6mC"
   },
   "id": "6RomPqxm_6mC"
  },
  {
   "cell_type": "code",
   "source": [
    "# Install a specific version of numpy first\n",
    "!pip install numpy==1.23.5 # You might need to adjust the numpy version based on your MONAI version\n",
    "\n",
    "# Install monai and torch\n",
    "!pip install monai\n",
    "!pip install torch"
   ],
   "metadata": {
    "id": "PJzrswjD3j4L"
   },
   "id": "PJzrswjD3j4L",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb3a5df9",
   "metadata": {
    "id": "cb3a5df9"
   },
   "source": [
    "#### In this Jupyter Notebook we will display the results after training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96000eda",
   "metadata": {
    "id": "96000eda"
   },
   "source": [
    "##### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea815e7f",
   "metadata": {
    "id": "ea815e7f"
   },
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "from glob import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.amp import autocast, GradScaler\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss, TverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import Dataset, CacheDataset,DataLoader\n",
    "from monai.utils import set_determinism\n",
    "from monai.networks.utils import one_hot\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    CropForegroundd,\n",
    "    Orientationd,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "6cb9bdee",
   "metadata": {
    "id": "6cb9bdee"
   },
   "source": [
    "##### Setting the path to the working directories"
   ]
  },
  {
   "cell_type": "code",
   "id": "790dbd62",
   "metadata": {
    "id": "790dbd62",
    "outputId": "867d751f-d7c1-4a3a-84f1-62eb15a00ce8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# The input paths for the prepared nifti files\n",
    "nif_path = ['drive/MyDrive/data_set_group_nif/nif_files_testing/images',\n",
    "            'drive/MyDrive/data_set_group_nif/nif_files_testing/labels',\n",
    "            'drive/MyDrive/data_set_group_nif/nif_files_training/images',\n",
    "            'drive/MyDrive/data_set_group_nif/nif_files_training/labels',]\n",
    "\n",
    "print(nif_path[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "drive/MyDrive/data_set_group_nif/nif_files_testing/images\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "7f290f77ce837ce1"
   },
   "cell_type": "markdown",
   "source": [
    "##### Define the function for data preprocessing"
   ],
   "id": "7f290f77ce837ce1"
  },
  {
   "metadata": {
    "id": "8d8f5fc427d9fc7e"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "def preprocess_data(data_path, batch_size=1, spatial_size=(256, 256, 16)):\n",
    "\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    # Create the dataset\n",
    "    test_data = sorted(glob(data_path[0] + f'/*'))\n",
    "    test_labels = sorted(glob(data_path[1] + f'/*'))\n",
    "\n",
    "    train_data = sorted(glob(data_path[2] + f'/*'))\n",
    "    train_labels = sorted(glob(data_path[3] + f'/*'))\n",
    "\n",
    "    train_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_data, train_labels)]\n",
    "    test_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_data, test_labels)]\n",
    "\n",
    "    # Transforms for the training with data augmentation\n",
    "    train_transforms = Compose(# Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]), # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]), # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")), # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),# Change the contrast of the image and gives the image pixels,\n",
    "                                                                                                            #values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"), # Crop foreground of the image\n",
    "            RandAffined(keys=['image', 'label'], prob=0.5, translate_range=10), # Randomly shift the image\n",
    "            RandRotated(keys=['image', 'label'], prob=0.5, range_x=10.0), # Randomly rotate the image\n",
    "            RandGaussianNoised(keys='image', prob=0.5), # Add random noise to the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size), # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]), # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Transforms for the testing\n",
    "    test_transforms = Compose(# Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]), # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]), # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")), # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),# Change the contrast of the image and gives the image pixels,\n",
    "                                                                                                            #values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"), # Crop foreground of the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size), # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]), # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the datasets\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
    "\n",
    "    test_ds = CacheDataset(data=test_files, transform=test_transforms)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "id": "8d8f5fc427d9fc7e"
  },
  {
   "cell_type": "markdown",
   "id": "33a723d6",
   "metadata": {
    "id": "33a723d6"
   },
   "source": [
    "##### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "sqj2Fmmwclih"
   },
   "id": "sqj2Fmmwclih"
  },
  {
   "cell_type": "code",
   "id": "b5586891",
   "metadata": {
    "id": "b5586891",
    "outputId": "7ed7943e-b63d-4a21-cb21-98780b0fd4d2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "data_in = preprocess_data(nif_path, batch_size=32, spatial_size=(256, 256, 16))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "Loading dataset: 100%|██████████| 748/748 [07:02<00:00,  1.77it/s]\n",
      "Loading dataset: 100%|██████████| 240/240 [02:31<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "15b1f3a791137aae",
   "metadata": {
    "id": "15b1f3a791137aae"
   },
   "source": [
    "##### Setting the device for training"
   ]
  },
  {
   "cell_type": "code",
   "id": "4425e0a7f3020fad",
   "metadata": {
    "id": "4425e0a7f3020fad",
    "outputId": "d1072225-6cce-4a99-cd71-90d19a6ad402",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# We do the training on the GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "40ff691e13ece641",
   "metadata": {
    "id": "40ff691e13ece641"
   },
   "source": [
    "##### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8ad17af36631361",
   "metadata": {
    "id": "d8ad17af36631361"
   },
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "156e8458c7fb1dc7",
   "metadata": {
    "id": "156e8458c7fb1dc7"
   },
   "source": [
    "##### Initialize the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a79dfc6615d0868",
   "metadata": {
    "id": "2a79dfc6615d0868"
   },
   "source": [
    "loss_function = TverskyLoss(\n",
    "    to_onehot_y=True,\n",
    "    softmax=True,\n",
    "    alpha=0.7,  # penalize false negatives more (missing tumors)\n",
    "    beta=0.3,\n",
    "    include_background=True\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5, amsgrad=True)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "id": "1506715d8d977110"
   },
   "cell_type": "markdown",
   "source": [
    "##### Define the training loop"
   ],
   "id": "1506715d8d977110"
  },
  {
   "metadata": {
    "id": "349d3416d78afc91"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 48,
   "source": [
    "def train(\n",
    "    model,\n",
    "    data_in,\n",
    "    num_classes,\n",
    "    loss_function,\n",
    "    optimizer,\n",
    "    max_epochs,\n",
    "    model_dir,\n",
    "    test_interval=1,\n",
    "    device=torch.device('cuda:0')\n",
    "):\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"none\", get_not_nans=False)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Tracking\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train, save_loss_test = [], []\n",
    "    save_metric_train, save_metric_test = [], []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"\\n--- Epoch {epoch + 1}/{max_epochs} ---\")\n",
    "        model.train()\n",
    "        train_loss_total = 0.0\n",
    "        train_dice_sum = torch.zeros(num_classes - 1, device=device)  # skip background\n",
    "        steps = 0\n",
    "\n",
    "        for step, batch_data in enumerate(train_loader):\n",
    "            volumes = batch_data[\"image\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(volumes)\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "            if device.type == 'cuda':\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds = torch.softmax(outputs, dim=1)\n",
    "                labels_onehot = one_hot(labels, num_classes=num_classes)\n",
    "                dice_scores = dice_metric(y_pred=preds, y=labels_onehot)\n",
    "                #Average dice scores over the batch dimension before accumulation\n",
    "                dice_scores = dice_scores.mean(dim=0)\n",
    "                if dice_scores.ndim > 1:\n",
    "                    dice_scores = dice_scores.squeeze()\n",
    "                train_dice_sum += dice_scores\n",
    "                train_loss_total += loss.item()\n",
    "                steps += 1\n",
    "\n",
    "            print(f\"Step {step+1}/{len(train_loader)} => \"\n",
    "                  f\"Loss: {loss.item():.4f} | \"\n",
    "                  f\"Liver Dice: {dice_scores[0].item():.4f} | \"\n",
    "                  f\"Tumor Dice: {dice_scores[1].item():.4f}\")\n",
    "\n",
    "        epoch_loss = train_loss_total / steps\n",
    "        epoch_dice = (train_dice_sum / steps).cpu().numpy()\n",
    "        avg_dice = epoch_dice.mean()\n",
    "\n",
    "        save_loss_train.append(epoch_loss)\n",
    "        save_metric_train.append(avg_dice)\n",
    "        np.save(os.path.join(model_dir, 'train_loss.npy'), save_loss_train)\n",
    "        np.save(os.path.join(model_dir, 'train_metric.npy'), save_metric_train)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch+1} Train Avg Loss: {epoch_loss:.4f} | \"\n",
    "              f\"Liver Dice: {epoch_dice[0]:.4f}, Tumor Dice: {epoch_dice[1]:.4f}, \"\n",
    "              f\"Avg Dice: {avg_dice:.4f}\")\n",
    "\n",
    "        # ---------- TESTING ----------\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "            model.eval()\n",
    "            test_loss_total = 0.0\n",
    "            test_dice_sum = torch.zeros(num_classes - 1, device=device)\n",
    "            steps = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for step, test_data in enumerate(test_loader):\n",
    "                    volumes = test_data[\"image\"].to(device)\n",
    "                    labels = test_data[\"label\"].to(device)\n",
    "\n",
    "                    with autocast(device_type=device.type):\n",
    "                        outputs = model(volumes)\n",
    "                        loss = loss_function(outputs, labels)\n",
    "\n",
    "                    preds = torch.softmax(outputs, dim=1)\n",
    "                    labels_onehot = one_hot(labels, num_classes=num_classes)\n",
    "                    dice_scores = dice_metric(y_pred=preds, y=labels_onehot)\n",
    "                    # Average dice scores over the batch dimension before accumulation\n",
    "                    dice_scores = dice_scores.mean(dim=0)\n",
    "                    if dice_scores.ndim > 1:\n",
    "                        dice_scores = dice_scores.squeeze()\n",
    "                    test_dice_sum += dice_scores\n",
    "                    test_loss_total += loss.item()\n",
    "                    steps += 1\n",
    "\n",
    "                    print(f\"Step {step+1}/{len(test_loader)} => \"\n",
    "                          f\"Loss: {loss.item():.4f} | \"\n",
    "                          f\"Liver Dice: {dice_scores[0].item():.4f} | \"\n",
    "                          f\"Tumor Dice: {dice_scores[1].item():.4f}\")\n",
    "\n",
    "            epoch_test_loss = test_loss_total / steps\n",
    "            epoch_test_dice = (test_dice_sum / steps).cpu().numpy()\n",
    "            avg_test_dice = epoch_test_dice.mean()\n",
    "\n",
    "            save_loss_test.append(epoch_test_loss)\n",
    "            save_metric_test.append(avg_test_dice)\n",
    "            np.save(os.path.join(model_dir, 'test_loss.npy'), save_loss_test)\n",
    "            np.save(os.path.join(model_dir, 'test_metric.npy'), save_metric_test)\n",
    "\n",
    "            print(f\"🔍 Epoch {epoch+1} Test Avg Loss: {epoch_test_loss:.4f} | \"\n",
    "                  f\"Liver Dice: {epoch_test_dice[0]:.4f}, Tumor Dice: {epoch_test_dice[1]:.4f}, \"\n",
    "                  f\"Avg Dice: {avg_test_dice:.4f}\")\n",
    "\n",
    "            if avg_test_dice > best_metric:\n",
    "                best_metric = avg_test_dice\n",
    "                best_metric_epoch = epoch + 1\n",
    "                model_path = os.path.join(model_dir, f\"best_model_epoch{epoch+1}_dice{best_metric:.4f}.pth\")\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"💾 Best model saved at epoch {epoch+1} with Avg Dice {best_metric:.4f}\")\n",
    "\n",
    "    print(f\"\\n🏁 Training complete. Best Avg Dice: {best_metric:.4f} at epoch {best_metric_epoch}\")\n"
   ],
   "id": "349d3416d78afc91"
  },
  {
   "cell_type": "markdown",
   "id": "8b4ab43200d91d61",
   "metadata": {
    "id": "8b4ab43200d91d61"
   },
   "source": [
    "##### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1a67f1a5a944836",
   "metadata": {
    "id": "d1a67f1a5a944836",
    "outputId": "238e8ef7-58ac-4aa4-8bee-f5bacb84fd51",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "model_dir = 'drive/MyDrive/trained_models/post_training_Unet'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "train(model=model,\n",
    "      data_in=data_in,\n",
    "      num_classes=3,\n",
    "      loss_function=loss_function,\n",
    "      optimizer=optimizer,\n",
    "      max_epochs=10,\n",
    "      model_dir=model_dir,\n",
    "      test_interval=1,\n",
    "      device=device\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
