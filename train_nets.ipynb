{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3a5df9",
   "metadata": {},
   "source": [
    "#### In this Jupyter Notebook we will display the results after training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96000eda",
   "metadata": {},
   "source": [
    "##### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea815e7f",
   "metadata": {},
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "from glob import glob\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss\n",
    "from monai.data import Dataset, CacheDataset,DataLoader\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    CropForegroundd,\n",
    "    Orientationd,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cb9bdee",
   "metadata": {},
   "source": [
    "##### Setting the path to the working directories"
   ]
  },
  {
   "cell_type": "code",
   "id": "790dbd62",
   "metadata": {},
   "source": [
    "# The input paths for the prepared nifti files\n",
    "nif_path = ['data_set_group_nif/nif_files_testing/images',\n",
    "            'data_set_group_nif/nif_files_testing/labels',\n",
    "            'data_set_group_nif/nif_files_training/images',\n",
    "            'data_set_group_nif/nif_files_training/labels',]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define the function for data preprocessing",
   "id": "7f290f77ce837ce1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_data(data_path, batch_size=1, spatial_size=(256, 256, 16)):\n",
    "\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    # Create the dataset\n",
    "    test_data = sorted(glob(data_path[0] + f'/*'))\n",
    "    test_labels = sorted(glob(data_path[1] + f'/*'))\n",
    "\n",
    "    train_data = sorted(glob(data_path[2] + f'/*'))\n",
    "    train_labels = sorted(glob(data_path[3] + f'/*'))\n",
    "\n",
    "    train_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_data, train_labels)]\n",
    "    test_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_data, test_labels)]\n",
    "\n",
    "    # Transforms for the training with data augmentation\n",
    "    train_transforms = Compose(# Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]), # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]), # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")), # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),# Change the contrast of the image and gives the image pixels,\n",
    "                                                                                                            #values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"), # Crop foreground of the image\n",
    "            RandAffined(keys=['image', 'label'], prob=0.5, translate_range=10), # Randomly shift the image\n",
    "            RandRotated(keys=['image', 'label'], prob=0.5, range_x=10.0), # Randomly rotate the image\n",
    "            RandGaussianNoised(keys='image', prob=0.5), # Add random noise to the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size), # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]), # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Transforms for the testing\n",
    "    test_transforms = Compose(# Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]), # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]), # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")), # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),# Change the contrast of the image and gives the image pixels,\n",
    "                                                                                                            #values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"), # Crop foreground of the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size), # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]), # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the datasets\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
    "\n",
    "    test_ds = CacheDataset(data=test_files, transform=test_transforms)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    '''for data in train_loader:\n",
    "        print(data[\"image\"].shape)\n",
    "        print(data[\"label\"].shape)\n",
    "\n",
    "    for data in test_loader:\n",
    "        print(data[\"image\"].shape)\n",
    "        print(data[\"label\"].shape)'''\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "id": "8d8f5fc427d9fc7e"
  },
  {
   "cell_type": "markdown",
   "id": "33a723d6",
   "metadata": {},
   "source": "##### Preprocess the data"
  },
  {
   "cell_type": "code",
   "id": "b5586891",
   "metadata": {},
   "source": [
    "data_in = preprocess_data(nif_path, batch_size=1, spatial_size=(512, 512, 16))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15b1f3a791137aae",
   "metadata": {},
   "source": [
    "##### Setting the device for training"
   ]
  },
  {
   "cell_type": "code",
   "id": "4425e0a7f3020fad",
   "metadata": {},
   "source": [
    "# We do the training on the GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40ff691e13ece641",
   "metadata": {},
   "source": [
    "##### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8ad17af36631361",
   "metadata": {},
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "156e8458c7fb1dc7",
   "metadata": {},
   "source": [
    "##### Initialize the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a79dfc6615d0868",
   "metadata": {},
   "source": [
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define the training loop",
   "id": "1506715d8d977110"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(\n",
    "        model,\n",
    "        data_in,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        max_epochs,\n",
    "        model_dir,\n",
    "        test_interval=1,\n",
    "        device=torch.device('cuda:0')\n",
    "    ):\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train = []\n",
    "    save_loss_test = []\n",
    "    save_metric_train = []\n",
    "    save_metric_test = []\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        train_step = 0\n",
    "        train_epoch_metric = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            train_step += 1\n",
    "            volumes = batch_data[\"image\"]\n",
    "            labels = batch_data[\"label\"]\n",
    "            labels = labels != 0\n",
    "            volumes = volumes.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(volumes)\n",
    "\n",
    "            train_loss = loss_function(outputs, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_metric = dice_metric(outputs, labels)\n",
    "            train_epoch_metric += train_metric\n",
    "\n",
    "            print(f\"{epoch + 1}/{max_epochs} and {train_step}/{len(train_loader) // train_loader.batch_size} => train_loss: {train_loss.item():.4f} and train_metric: {train_metric:.4f}\")\n",
    "\n",
    "        print('Saving training data after epoch: ' + str(epoch + 1))\n",
    "        train_epoch_loss /= train_step\n",
    "        print(f\"epoch {epoch + 1} average training loss: {train_epoch_loss:.4f}\")\n",
    "        save_loss_train.append(train_epoch_loss)\n",
    "        np.save(os.path.join(model_dir, 'train_loss.npy'), save_loss_train)\n",
    "\n",
    "        train_epoch_metric /= train_step\n",
    "        print(f\"epoch {epoch + 1} average training metric: {train_epoch_metric:.4f}\")\n",
    "        save_metric_train.append(train_epoch_metric)\n",
    "        np.save(os.path.join(model_dir, 'train_metric.npy'), save_metric_train)\n",
    "\n",
    "        if (epoch+1) % test_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_epoch_loss = 0\n",
    "                test_metric = 0\n",
    "                test_step = 0\n",
    "                test_epoch_metric = 0\n",
    "\n",
    "                for test_data in test_loader:\n",
    "                    test_step += 1\n",
    "                    volumes = test_data[\"image\"]\n",
    "                    labels = test_data[\"label\"]\n",
    "                    labels = labels != 0\n",
    "                    volumes = volumes.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(volumes)\n",
    "\n",
    "                    test_loss = loss_function(outputs, labels)\n",
    "\n",
    "                    test_epoch_loss += test_loss.item()\n",
    "                    test_metric = dice_metric(outputs, labels)\n",
    "                    test_epoch_metric += test_metric\n",
    "\n",
    "                    print(f\"{epoch + 1}/{max_epochs} and {test_step}/{len(test_loader) // test_loader.batch_size} => test_loss: {test_loss.item():.4f} and test_metric: {test_metric:.4f}\")\n",
    "\n",
    "                print('Saving testing data after epoch: ' + str(epoch + 1))\n",
    "                test_epoch_loss /= test_step\n",
    "                print(f\"epoch {epoch + 1} average testing loss: {test_epoch_loss:.4f}\")\n",
    "                save_loss_test.append(test_epoch_loss)\n",
    "                np.save(os.path.join(model_dir, 'test_loss.npy'), save_loss_test)\n",
    "\n",
    "                test_epoch_metric /= test_step\n",
    "                print(f\"epoch {epoch + 1} average testing metric: {test_epoch_metric:.4f}\")\n",
    "                save_metric_test.append(test_epoch_metric)\n",
    "                np.save(os.path.join(model_dir, 'test_metric.npy'), save_metric_test)\n",
    "\n",
    "                if test_epoch_metric > best_metric:\n",
    "                    best_metric = test_epoch_metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_model.pth\"))\n",
    "\n",
    "                print(f\"current epoch: {epoch + 1} current test Dice coefficient: {test_epoch_metric:.4f}\"\n",
    "                    f\"\\nbest metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "\n",
    "    print(f\"train completed => best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ],
   "id": "349d3416d78afc91"
  },
  {
   "cell_type": "markdown",
   "id": "8b4ab43200d91d61",
   "metadata": {},
   "source": [
    "##### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1a67f1a5a944836",
   "metadata": {},
   "source": [
    "os.makedirs('post_training', exist_ok=true)\n",
    "\n",
    "train(model,\n",
    "      data_in,\n",
    "      loss_function,\n",
    "      optimizer,\n",
    "      10,\n",
    "      '../post_training_best',\n",
    "      test_interval=100,\n",
    "      device=device\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:liver-segmentation] *",
   "language": "python",
   "name": "conda-env-liver-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
