{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3a5df9",
   "metadata": {},
   "source": [
    "#### In this Jupyter Notebook we will display the results after training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96000eda",
   "metadata": {},
   "source": [
    "##### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea815e7f",
   "metadata": {},
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss, FocalTverskyLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import Dataset, CacheDataset,DataLoader\n",
    "from monai.utils import set_determinism\n",
    "from monai.networks.utils import one_hot\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    RandGaussianNoised,\n",
    "    CropForegroundd,\n",
    "    Orientationd,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cb9bdee",
   "metadata": {},
   "source": [
    "##### Setting the path to the working directories"
   ]
  },
  {
   "cell_type": "code",
   "id": "790dbd62",
   "metadata": {},
   "source": [
    "# The input paths for the prepared nifti files\n",
    "nif_path = ['data_set_group_nif/nif_files_testing/images',\n",
    "            'data_set_group_nif/nif_files_testing/labels',\n",
    "            'data_set_group_nif/nif_files_training/images',\n",
    "            'data_set_group_nif/nif_files_training/labels',]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define the function for data preprocessing",
   "id": "7f290f77ce837ce1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_data(data_path, batch_size=1, spatial_size=(256, 256, 16)):\n",
    "\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    # Create the dataset\n",
    "    test_data = sorted(glob(data_path[0] + f'/*'))\n",
    "    test_labels = sorted(glob(data_path[1] + f'/*'))\n",
    "\n",
    "    train_data = sorted(glob(data_path[2] + f'/*'))\n",
    "    train_labels = sorted(glob(data_path[3] + f'/*'))\n",
    "\n",
    "    train_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_data, train_labels)]\n",
    "    test_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_data, test_labels)]\n",
    "\n",
    "    # Transforms for the training with data augmentation\n",
    "    train_transforms = Compose(# Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]), # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]), # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")), # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),# Change the contrast of the image and gives the image pixels,\n",
    "                                                                                                            #values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"), # Crop foreground of the image\n",
    "            RandAffined(keys=['image', 'label'], prob=0.5, translate_range=10), # Randomly shift the image\n",
    "            RandRotated(keys=['image', 'label'], prob=0.5, range_x=10.0), # Randomly rotate the image\n",
    "            RandGaussianNoised(keys='image', prob=0.5), # Add random noise to the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size), # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]), # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Transforms for the testing\n",
    "    test_transforms = Compose(# Compose transforms together\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]), # Load the images\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"]), # Ensure the channel is the first dimension of the image\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")), # Resample the images\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), # Change the orientation of the image\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=200, b_min=0.0, b_max=1.0, clip=True),# Change the contrast of the image and gives the image pixels,\n",
    "                                                                                                            #values between 0 and 1\n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"), # Crop foreground of the image\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size), # Resize the image\n",
    "            ToTensord(keys=[\"image\", \"label\"]), # Convert the images to tensors\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the datasets\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
    "\n",
    "    test_ds = CacheDataset(data=test_files, transform=test_transforms)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    '''for data in train_loader:\n",
    "        print(data[\"image\"].shape)\n",
    "        print(data[\"label\"].shape)\n",
    "\n",
    "    for data in test_loader:\n",
    "        print(data[\"image\"].shape)\n",
    "        print(data[\"label\"].shape)'''\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "id": "8d8f5fc427d9fc7e"
  },
  {
   "cell_type": "markdown",
   "id": "33a723d6",
   "metadata": {},
   "source": "##### Preprocess the data"
  },
  {
   "cell_type": "code",
   "id": "b5586891",
   "metadata": {},
   "source": [
    "data_in = preprocess_data(nif_path, batch_size=1, spatial_size=(512, 512, 16))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15b1f3a791137aae",
   "metadata": {},
   "source": [
    "##### Setting the device for training"
   ]
  },
  {
   "cell_type": "code",
   "id": "4425e0a7f3020fad",
   "metadata": {},
   "source": [
    "# We do the training on the GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40ff691e13ece641",
   "metadata": {},
   "source": [
    "##### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8ad17af36631361",
   "metadata": {},
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "156e8458c7fb1dc7",
   "metadata": {},
   "source": [
    "##### Initialize the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a79dfc6615d0868",
   "metadata": {},
   "source": [
    "loss_function = FocalTverskyLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5, amsgrad=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define the training loop",
   "id": "1506715d8d977110"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(\n",
    "    model,\n",
    "    data_in,\n",
    "    num_classes,\n",
    "    max_epochs,\n",
    "    model_dir,\n",
    "    test_interval=1,\n",
    "    device=torch.device('cuda:0')\n",
    "):\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    # Metric setup\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Tracking\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train, save_loss_test = [], []\n",
    "    save_metric_train, save_metric_test = [], []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"\\n--- Epoch {epoch + 1}/{max_epochs} ---\")\n",
    "        model.train()\n",
    "        train_loss_total, train_metric_total = 0.0, 0.0\n",
    "\n",
    "        for step, batch_data in enumerate(train_loader):\n",
    "            volumes = batch_data[\"image\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(volumes)  # shape: [B, C, D, H, W]\n",
    "\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Metric computation\n",
    "            with torch.no_grad():\n",
    "                preds = torch.softmax(outputs, dim=1)\n",
    "                labels_onehot = one_hot(labels, num_classes=num_classes)\n",
    "                dice = dice_metric(y_pred=preds, y=labels_onehot)\n",
    "\n",
    "            train_loss_total += loss.item()\n",
    "            train_metric_total += dice.item()\n",
    "\n",
    "            print(f\"Step {step+1}/{len(train_loader)} => Train Loss: {loss.item():.4f} | Dice: {dice.item():.4f}\")\n",
    "\n",
    "        epoch_loss = train_loss_total / len(train_loader)\n",
    "        epoch_metric = train_metric_total / len(train_loader)\n",
    "\n",
    "        save_loss_train.append(epoch_loss)\n",
    "        save_metric_train.append(epoch_metric)\n",
    "        np.save(os.path.join(model_dir, 'train_loss.npy'), save_loss_train)\n",
    "        np.save(os.path.join(model_dir, 'train_metric.npy'), save_metric_train)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Train Avg Loss: {epoch_loss:.4f}, Dice: {epoch_metric:.4f}\")\n",
    "\n",
    "        # ---------- TESTING ----------\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "            model.eval()\n",
    "            test_loss_total, test_metric_total = 0.0, 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for step, test_data in enumerate(test_loader):\n",
    "                    volumes = test_data[\"image\"].to(device)\n",
    "                    labels = test_data[\"label\"].to(device)\n",
    "\n",
    "                    with autocast():\n",
    "                        outputs = model(volumes)\n",
    "                        loss = loss_function(outputs, labels)\n",
    "\n",
    "                    preds = torch.softmax(outputs, dim=1)\n",
    "                    labels_onehot = one_hot(labels, num_classes=num_classes)\n",
    "                    dice = dice_metric(y_pred=preds, y=labels_onehot)\n",
    "\n",
    "                    test_loss_total += loss.item()\n",
    "                    test_metric_total += dice.item()\n",
    "\n",
    "                    print(f\"Step {step+1}/{len(test_loader)} => Test Loss: {loss.item():.4f} | Dice: {dice.item():.4f}\")\n",
    "\n",
    "            epoch_test_loss = test_loss_total / len(test_loader)\n",
    "            epoch_test_metric = test_metric_total / len(test_loader)\n",
    "\n",
    "            save_loss_test.append(epoch_test_loss)\n",
    "            save_metric_test.append(epoch_test_metric)\n",
    "            np.save(os.path.join(model_dir, 'test_loss.npy'), save_loss_test)\n",
    "            np.save(os.path.join(model_dir, 'test_metric.npy'), save_metric_test)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} Test Avg Loss: {epoch_test_loss:.4f}, Dice: {epoch_test_metric:.4f}\")\n",
    "\n",
    "            if epoch_test_metric > best_metric:\n",
    "                best_metric = epoch_test_metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                model_path = os.path.join(model_dir, f\"best_model_epoch{epoch+1}_dice{best_metric:.4f}.pth\")\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"✔️ Best model updated at epoch {epoch+1} with Dice {best_metric:.4f}\")\n",
    "\n",
    "    print(f\"\\n✅ Training complete. Best Dice: {best_metric:.4f} at epoch {best_metric_epoch}\")\n"
   ],
   "id": "349d3416d78afc91"
  },
  {
   "cell_type": "markdown",
   "id": "8b4ab43200d91d61",
   "metadata": {},
   "source": [
    "##### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1a67f1a5a944836",
   "metadata": {},
   "source": [
    "model_dir = '../post_training_Unet'\n",
    "os.makedirs(model_dir, exist_ok=true)\n",
    "\n",
    "train(model=model,\n",
    "      data_in=data_in,\n",
    "      num_classes=3,\n",
    "      loss_function=loss_function,\n",
    "      optimizer=optimizer,\n",
    "      max_epochs=100,\n",
    "      model_dir=model_dir,\n",
    "      test_interval=1,\n",
    "      device=device\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:liver-segmentation] *",
   "language": "python",
   "name": "conda-env-liver-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
