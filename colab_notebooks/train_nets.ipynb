{
  "cells": [
    {
      "metadata": {
        "id": "90627602666a6128"
      },
      "cell_type": "markdown",
      "source": [
        "##### Run cell only in GoogleColab"
      ],
      "id": "90627602666a6128"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Mrd0TKmS3CQd",
        "outputId": "adf58f0b-249b-4491-8759-2601cbc53fbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Mrd0TKmS3CQd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Installing dependencies (run cell only in GoogleColab)"
      ],
      "metadata": {
        "id": "6RomPqxm_6mC"
      },
      "id": "6RomPqxm_6mC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install monai and torch\n",
        "!pip install monai\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "WnzGkvbXULAj"
      },
      "id": "WnzGkvbXULAj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cb3a5df9",
      "metadata": {
        "id": "cb3a5df9"
      },
      "source": [
        "#### In this Jupyter Notebook we will display the results after training of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96000eda",
      "metadata": {
        "id": "96000eda"
      },
      "source": [
        "##### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "id": "ea815e7f",
      "metadata": {
        "id": "ea815e7f"
      },
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "from glob import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.losses import DiceLoss, TverskyLoss, DiceFocalLoss\n",
        "from monai.data import Dataset, CacheDataset, DataLoader\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    ScaleIntensityRanged,\n",
        "    RandAffined,\n",
        "    RandFlipd,\n",
        "    RandGaussianNoised,\n",
        "    CropForegroundd,\n",
        "    Orientationd,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    EnsureTyped,\n",
        ")\n",
        "\n",
        "from monai.data.image_reader import NibabelReader"
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "id": "6cb9bdee",
      "metadata": {
        "id": "6cb9bdee"
      },
      "source": [
        "##### Setting the path to the working directories"
      ]
    },
    {
      "cell_type": "code",
      "id": "790dbd62",
      "metadata": {
        "id": "790dbd62",
        "outputId": "8b0271b3-89cb-44fc-dd45-be24394185af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The input paths for the prepared nifti files\n",
        "nif_path = ['drive/MyDrive/data_set_group_nif/nif_files_testing/images',\n",
        "            'drive/MyDrive/data_set_group_nif/nif_files_testing/labels',\n",
        "            'drive/MyDrive/data_set_group_nif/nif_files_training/images',\n",
        "            'drive/MyDrive/data_set_group_nif/nif_files_training/labels',]\n",
        "\n",
        "print(nif_path[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/data_set_group_nif/nif_files_testing/images\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "id": "7f290f77ce837ce1"
      },
      "cell_type": "markdown",
      "source": [
        "##### Define the function for data preprocessing"
      ],
      "id": "7f290f77ce837ce1"
    },
    {
      "metadata": {
        "id": "8d8f5fc427d9fc7e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 5,
      "source": [
        "def preprocess_data(data_path, batch_size=8, spatial_size=(256, 256, 16), pixdim=(1.5, 1.5, 2.0)):\n",
        "\n",
        "    set_determinism(seed=0)\n",
        "\n",
        "    # Create the dataset\n",
        "    test_data = sorted(glob(data_path[0] + f'/*'))\n",
        "    test_labels = sorted(glob(data_path[1] + f'/*'))\n",
        "\n",
        "    train_data = sorted(glob(data_path[2] + f'/*'))\n",
        "    train_labels = sorted(glob(data_path[3] + f'/*'))\n",
        "\n",
        "    train_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_data, train_labels)]\n",
        "    test_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(test_data, test_labels)]\n",
        "\n",
        "    # Transforms for the training with data augmentation\n",
        "    train_transforms = Compose([\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),  # Load the images\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),  # Ensure the channel is the first dimension of the image\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),  # Resample the images\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),  # Change the orientation of the image\n",
        "        ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
        "        # Change the contrast of the image and gives the image pixels,\n",
        "        # values between 0 and 1\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_smaller=True),\n",
        "\n",
        "        RandAffined(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            prob=0.7,\n",
        "            translate_range=(10, 10, 5),\n",
        "            rotate_range=(0, 0, np.pi / 15),\n",
        "            scale_range=(0.1, 0.1, 0.1),\n",
        "            mode=(\"bilinear\", \"nearest\")\n",
        "        ),\n",
        "        RandGaussianNoised(keys=\"image\", prob=0.5),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "\n",
        "        Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size),  # Resize the image\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ToTensord(keys=[\"image\", \"label\"]),  # Convert the images to tensors\n",
        "    ])\n",
        "\n",
        "    # Transforms for the testing\n",
        "    test_transforms = Compose(# Compose transforms together\n",
        "        [\n",
        "            LoadImaged(keys=[\"image\", \"label\"]),  # Load the images\n",
        "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),  # Ensure the channel is the first dimension of the image\n",
        "            Spacingd(keys=[\"image\", \"label\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            # Resample the images\n",
        "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),  # Change the orientation of the image\n",
        "            ScaleIntensityRanged(keys=[\"image\"], a_min=-200, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
        "            # Change the contrast of the image and gives the image pixels,\n",
        "            # values between 0 and 1\n",
        "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_smaller=True),  # Crop foreground of the image\n",
        "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size),  # Resize the image\n",
        "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "            ToTensord(keys=[\"image\", \"label\"]),  # Convert the images to tensors\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Create the datasets\n",
        "    train_ds = CacheDataset(data=train_files, transform=train_transforms)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
        "\n",
        "    test_ds = CacheDataset(data=test_files, transform=test_transforms)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "id": "8d8f5fc427d9fc7e"
    },
    {
      "cell_type": "markdown",
      "id": "33a723d6",
      "metadata": {
        "id": "33a723d6"
      },
      "source": [
        "##### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "id": "b5586891",
      "metadata": {
        "id": "b5586891",
        "outputId": "ab7e9f80-1347-4ed9-acb6-b3c64f3fc3e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save the metadata of the entire training set\n",
        "data_in = preprocess_data(\n",
        "    nif_path,\n",
        "    batch_size=2,  # start conservative\n",
        "    spatial_size=(128, 128, 32),\n",
        "    pixdim=(0.7871384, 0.7871384, 1.2131842)\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 748/748 [15:08<00:00,  1.21s/it]\n",
            "Loading dataset: 100%|██████████| 240/240 [06:52<00:00,  1.72s/it]\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "id": "15b1f3a791137aae",
      "metadata": {
        "id": "15b1f3a791137aae"
      },
      "source": [
        "##### Setting the device for training"
      ]
    },
    {
      "cell_type": "code",
      "id": "4425e0a7f3020fad",
      "metadata": {
        "id": "4425e0a7f3020fad",
        "outputId": "cbdef050-c006-47d3-a36d-9ccdc856db45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We do the training on the GPU\n",
        "device = torch.device(\"cuda:0\")\n",
        "print(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "id": "40ff691e13ece641",
      "metadata": {
        "id": "40ff691e13ece641"
      },
      "source": [
        "##### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "id": "d8ad17af36631361",
      "metadata": {
        "id": "d8ad17af36631361"
      },
      "source": [
        "model = UNet(\n",
        "  spatial_dims=3,\n",
        "  in_channels=1,\n",
        "  out_channels=2,\n",
        "  channels=(16, 32, 64, 128),\n",
        "  strides=(2, 2, 2),\n",
        "  num_res_units=2,\n",
        "  norm=Norm.BATCH,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "model = model.to(device)"
      ],
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "id": "156e8458c7fb1dc7",
      "metadata": {
        "id": "156e8458c7fb1dc7"
      },
      "source": [
        "##### Initialize the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "id": "2a79dfc6615d0868",
      "metadata": {
        "id": "2a79dfc6615d0868"
      },
      "source": [
        "loss_function = DiceFocalLoss(to_onehot_y=True, softmax=True, lambda_focal=0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5, amsgrad=True)"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_metric(y_pred, y):\n",
        "    dice_loss = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "    dice_coeff = 1 - dice_loss(y_pred, y).item()\n",
        "    return dice_coeff"
      ],
      "metadata": {
        "id": "IMrU0c6yQCf0"
      },
      "id": "IMrU0c6yQCf0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1506715d8d977110"
      },
      "cell_type": "markdown",
      "source": [
        "##### Define the training loop"
      ],
      "id": "1506715d8d977110"
    },
    {
      "metadata": {
        "id": "349d3416d78afc91"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 10,
      "source": [
        "# Function for training the model\n",
        "def train(model, data_in, loss_function, optimizer, max_epochs, model_dir, test_interval=1,\n",
        "          device=torch.device('cuda:0')):\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    save_loss_train = []\n",
        "    save_loss_test = []\n",
        "    save_metric_train = []\n",
        "    save_metric_test = []\n",
        "    train_loader, test_loader = data_in\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        train_epoch_loss = 0\n",
        "        train_step = 0\n",
        "        train_epoch_metric = 0\n",
        "\n",
        "        for batch_data in train_loader:\n",
        "            train_step += 1\n",
        "            volumes = batch_data[\"image\"]\n",
        "            labels = batch_data[\"label\"]\n",
        "            labels = labels != 0\n",
        "            volumes = volumes.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(volumes)\n",
        "\n",
        "            train_loss = loss_function(outputs, labels)\n",
        "\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_epoch_loss += train_loss.item()\n",
        "            train_metric = dice_metric(outputs, labels)\n",
        "            train_epoch_metric += train_metric\n",
        "\n",
        "            print(\n",
        "                f\"{epoch + 1}/{max_epochs} and {train_step}/{len(train_loader)} => train_loss: {train_loss.item():.4f} and train_metric: {train_metric:.4f}\")\n",
        "\n",
        "        print('Saving training data after epoch: ' + str(epoch + 1))\n",
        "        train_epoch_loss /= train_step\n",
        "        print(f\"epoch {epoch + 1} average training loss: {train_epoch_loss:.4f}\")\n",
        "        save_loss_train.append(train_epoch_loss)\n",
        "        np.save(os.path.join(model_dir, 'train_loss.npy'), save_loss_train)\n",
        "\n",
        "        train_epoch_metric /= train_step\n",
        "        print(f\"epoch {epoch + 1} average training metric: {train_epoch_metric:.4f}\")\n",
        "        save_metric_train.append(train_epoch_metric)\n",
        "        np.save(os.path.join(model_dir, 'train_metric.npy'), save_metric_train)\n",
        "\n",
        "        if (epoch + 1) % test_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_epoch_loss = 0\n",
        "                test_metric = 0\n",
        "                test_step = 0\n",
        "                test_epoch_metric = 0\n",
        "\n",
        "                for test_data in test_loader:\n",
        "                    test_step += 1\n",
        "                    volumes = test_data[\"image\"]\n",
        "                    labels = test_data[\"label\"]\n",
        "                    labels = labels != 0\n",
        "                    volumes = volumes.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    outputs = model(volumes)\n",
        "\n",
        "                    test_loss = loss_function(outputs, labels)\n",
        "\n",
        "                    test_epoch_loss += test_loss.item()\n",
        "                    test_metric = dice_metric(outputs, labels)\n",
        "                    test_epoch_metric += test_metric\n",
        "\n",
        "                    print(\n",
        "                        f\"{epoch + 1}/{max_epochs} and {test_step}/{len(test_loader)} => test_loss: {test_loss.item():.4f} and test_metric: {test_metric:.4f}\")\n",
        "\n",
        "                print('Saving testing data after epoch: ' + str(epoch + 1))\n",
        "                test_epoch_loss /= test_step\n",
        "                print(f\"epoch {epoch + 1} average testing loss: {test_epoch_loss:.4f}\")\n",
        "                save_loss_test.append(test_epoch_loss)\n",
        "                np.save(os.path.join(model_dir, 'test_loss.npy'), save_loss_test)\n",
        "\n",
        "                test_epoch_metric /= test_step\n",
        "                print(f\"epoch {epoch + 1} average testing metric: {test_epoch_metric:.4f}\")\n",
        "                save_metric_test.append(test_epoch_metric)\n",
        "                np.save(os.path.join(model_dir, 'test_metric.npy'), save_metric_test)\n",
        "\n",
        "                if test_epoch_metric > best_metric:\n",
        "                    best_metric = test_epoch_metric\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_model.pth\"))\n",
        "\n",
        "                print(f\"current epoch: {epoch + 1} current test Dice coefficient: {test_epoch_metric:.4f}\"\n",
        "                      f\"\\nbest metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "\n",
        "    print(f\"train completed => best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
      ],
      "id": "349d3416d78afc91"
    },
    {
      "cell_type": "markdown",
      "id": "8b4ab43200d91d61",
      "metadata": {
        "id": "8b4ab43200d91d61"
      },
      "source": [
        "##### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "id": "d1a67f1a5a944836",
      "metadata": {
        "id": "d1a67f1a5a944836",
        "outputId": "042ec292-4a50-4cf1-c260-08d30fad138e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_dir = 'drive/MyDrive/trained_models/post_training_UNet_128_128_32'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "train(model=model,\n",
        "      data_in=data_in,\n",
        "      loss_function=loss_function,\n",
        "      optimizer=optimizer,\n",
        "      max_epochs=100,\n",
        "      model_dir=model_dir,\n",
        "      test_interval=4,\n",
        "      device=device\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/100 and 1/374 => train_loss: 0.7062 and train_metric: 0.5059\n",
            "1/100 and 2/374 => train_loss: 0.7384 and train_metric: 0.4475\n",
            "1/100 and 3/374 => train_loss: 0.7131 and train_metric: 0.4967\n",
            "1/100 and 4/374 => train_loss: 0.6887 and train_metric: 0.5411\n",
            "1/100 and 5/374 => train_loss: 0.6811 and train_metric: 0.5541\n",
            "1/100 and 6/374 => train_loss: 0.6609 and train_metric: 0.5888\n",
            "1/100 and 7/374 => train_loss: 0.6926 and train_metric: 0.5327\n",
            "1/100 and 8/374 => train_loss: 0.7378 and train_metric: 0.4488\n",
            "1/100 and 9/374 => train_loss: 0.7058 and train_metric: 0.5099\n",
            "1/100 and 10/374 => train_loss: 0.6802 and train_metric: 0.5546\n",
            "1/100 and 11/374 => train_loss: 0.6542 and train_metric: 0.6029\n",
            "1/100 and 12/374 => train_loss: 0.6763 and train_metric: 0.5613\n",
            "1/100 and 13/374 => train_loss: 0.7424 and train_metric: 0.4401\n",
            "1/100 and 14/374 => train_loss: 0.7315 and train_metric: 0.4616\n",
            "1/100 and 15/374 => train_loss: 0.7044 and train_metric: 0.5124\n",
            "1/100 and 16/374 => train_loss: 0.6752 and train_metric: 0.5628\n",
            "1/100 and 17/374 => train_loss: 0.6398 and train_metric: 0.6241\n",
            "1/100 and 18/374 => train_loss: 0.6425 and train_metric: 0.6185\n",
            "1/100 and 19/374 => train_loss: 0.7253 and train_metric: 0.4713\n",
            "1/100 and 20/374 => train_loss: 0.7325 and train_metric: 0.4579\n",
            "1/100 and 21/374 => train_loss: 0.6863 and train_metric: 0.5430\n",
            "1/100 and 22/374 => train_loss: 0.6556 and train_metric: 0.5993\n",
            "1/100 and 23/374 => train_loss: 0.7102 and train_metric: 0.5037\n",
            "1/100 and 24/374 => train_loss: 0.7319 and train_metric: 0.4605\n",
            "1/100 and 25/374 => train_loss: 0.6878 and train_metric: 0.5402\n",
            "1/100 and 26/374 => train_loss: 0.6493 and train_metric: 0.6086\n",
            "1/100 and 27/374 => train_loss: 0.6591 and train_metric: 0.5932\n",
            "1/100 and 28/374 => train_loss: 0.7250 and train_metric: 0.4739\n",
            "1/100 and 29/374 => train_loss: 0.6966 and train_metric: 0.5220\n",
            "1/100 and 30/374 => train_loss: 0.6455 and train_metric: 0.6142\n",
            "1/100 and 31/374 => train_loss: 0.6472 and train_metric: 0.6113\n",
            "1/100 and 32/374 => train_loss: 0.7189 and train_metric: 0.4842\n",
            "1/100 and 33/374 => train_loss: 0.7403 and train_metric: 0.4446\n",
            "1/100 and 34/374 => train_loss: 0.7144 and train_metric: 0.4954\n",
            "1/100 and 35/374 => train_loss: 0.6740 and train_metric: 0.5674\n",
            "1/100 and 36/374 => train_loss: 0.6460 and train_metric: 0.6169\n",
            "1/100 and 37/374 => train_loss: 0.6324 and train_metric: 0.6424\n",
            "1/100 and 38/374 => train_loss: 0.6586 and train_metric: 0.5960\n",
            "1/100 and 39/374 => train_loss: 0.7374 and train_metric: 0.4504\n",
            "1/100 and 40/374 => train_loss: 0.7276 and train_metric: 0.4693\n",
            "1/100 and 41/374 => train_loss: 0.6992 and train_metric: 0.5230\n",
            "1/100 and 42/374 => train_loss: 0.6662 and train_metric: 0.5793\n",
            "1/100 and 43/374 => train_loss: 0.6493 and train_metric: 0.6108\n",
            "1/100 and 44/374 => train_loss: 0.6480 and train_metric: 0.6114\n",
            "1/100 and 45/374 => train_loss: 0.6825 and train_metric: 0.5502\n",
            "1/100 and 46/374 => train_loss: 0.7385 and train_metric: 0.4479\n",
            "1/100 and 47/374 => train_loss: 0.7170 and train_metric: 0.4902\n",
            "1/100 and 48/374 => train_loss: 0.6880 and train_metric: 0.5438\n",
            "1/100 and 49/374 => train_loss: 0.6711 and train_metric: 0.5742\n",
            "1/100 and 50/374 => train_loss: 0.6721 and train_metric: 0.5704\n",
            "1/100 and 51/374 => train_loss: 0.7077 and train_metric: 0.5062\n",
            "1/100 and 52/374 => train_loss: 0.7363 and train_metric: 0.4518\n",
            "1/100 and 53/374 => train_loss: 0.7118 and train_metric: 0.4993\n",
            "1/100 and 54/374 => train_loss: 0.6749 and train_metric: 0.5661\n",
            "1/100 and 55/374 => train_loss: 0.6471 and train_metric: 0.6141\n",
            "1/100 and 56/374 => train_loss: 0.6535 and train_metric: 0.6041\n",
            "1/100 and 57/374 => train_loss: 0.7123 and train_metric: 0.4982\n",
            "1/100 and 58/374 => train_loss: 0.7069 and train_metric: 0.5036\n",
            "1/100 and 59/374 => train_loss: 0.7138 and train_metric: 0.4950\n",
            "1/100 and 60/374 => train_loss: 0.7220 and train_metric: 0.4796\n",
            "1/100 and 61/374 => train_loss: 0.6838 and train_metric: 0.5497\n",
            "1/100 and 62/374 => train_loss: 0.6610 and train_metric: 0.5909\n",
            "1/100 and 63/374 => train_loss: 0.6500 and train_metric: 0.6100\n",
            "1/100 and 64/374 => train_loss: 0.6867 and train_metric: 0.5467\n",
            "1/100 and 65/374 => train_loss: 0.7353 and train_metric: 0.4541\n",
            "1/100 and 66/374 => train_loss: 0.7357 and train_metric: 0.4534\n",
            "1/100 and 67/374 => train_loss: 0.7118 and train_metric: 0.4991\n",
            "1/100 and 68/374 => train_loss: 0.6869 and train_metric: 0.5444\n",
            "1/100 and 69/374 => train_loss: 0.6660 and train_metric: 0.5811\n",
            "1/100 and 70/374 => train_loss: 0.6578 and train_metric: 0.5960\n",
            "1/100 and 71/374 => train_loss: 0.7248 and train_metric: 0.4736\n",
            "1/100 and 72/374 => train_loss: 0.6798 and train_metric: 0.5585\n",
            "1/100 and 73/374 => train_loss: 0.7399 and train_metric: 0.4448\n",
            "1/100 and 74/374 => train_loss: 0.7057 and train_metric: 0.5111\n",
            "1/100 and 75/374 => train_loss: 0.6595 and train_metric: 0.5933\n",
            "1/100 and 76/374 => train_loss: 0.6600 and train_metric: 0.5928\n",
            "1/100 and 77/374 => train_loss: 0.7257 and train_metric: 0.4730\n",
            "1/100 and 78/374 => train_loss: 0.6881 and train_metric: 0.5414\n",
            "1/100 and 79/374 => train_loss: 0.6675 and train_metric: 0.5786\n",
            "1/100 and 80/374 => train_loss: 0.7167 and train_metric: 0.4892\n",
            "1/100 and 81/374 => train_loss: 0.7396 and train_metric: 0.4437\n",
            "1/100 and 82/374 => train_loss: 0.7431 and train_metric: 0.4380\n",
            "1/100 and 83/374 => train_loss: 0.7355 and train_metric: 0.4529\n",
            "1/100 and 84/374 => train_loss: 0.7145 and train_metric: 0.4946\n",
            "1/100 and 85/374 => train_loss: 0.6892 and train_metric: 0.5407\n",
            "1/100 and 86/374 => train_loss: 0.6636 and train_metric: 0.5857\n",
            "1/100 and 87/374 => train_loss: 0.6595 and train_metric: 0.5933\n",
            "1/100 and 88/374 => train_loss: 0.6726 and train_metric: 0.5697\n",
            "1/100 and 89/374 => train_loss: 0.7359 and train_metric: 0.4509\n",
            "1/100 and 90/374 => train_loss: 0.7348 and train_metric: 0.4540\n",
            "1/100 and 91/374 => train_loss: 0.7124 and train_metric: 0.4968\n",
            "1/100 and 92/374 => train_loss: 0.6935 and train_metric: 0.5322\n",
            "1/100 and 93/374 => train_loss: 0.6674 and train_metric: 0.5782\n",
            "1/100 and 94/374 => train_loss: 0.6597 and train_metric: 0.5912\n",
            "1/100 and 95/374 => train_loss: 0.7189 and train_metric: 0.4839\n",
            "1/100 and 96/374 => train_loss: 0.7418 and train_metric: 0.4405\n",
            "1/100 and 97/374 => train_loss: 0.7249 and train_metric: 0.4737\n",
            "1/100 and 98/374 => train_loss: 0.7042 and train_metric: 0.5121\n",
            "1/100 and 99/374 => train_loss: 0.6826 and train_metric: 0.5516\n",
            "1/100 and 100/374 => train_loss: 0.6602 and train_metric: 0.5905\n",
            "1/100 and 101/374 => train_loss: 0.6582 and train_metric: 0.5924\n",
            "1/100 and 102/374 => train_loss: 0.6886 and train_metric: 0.5406\n",
            "1/100 and 103/374 => train_loss: 0.7390 and train_metric: 0.4462\n",
            "1/100 and 104/374 => train_loss: 0.6989 and train_metric: 0.5222\n",
            "1/100 and 105/374 => train_loss: 0.6442 and train_metric: 0.6194\n",
            "1/100 and 106/374 => train_loss: 0.6567 and train_metric: 0.5991\n",
            "1/100 and 107/374 => train_loss: 0.7430 and train_metric: 0.4385\n",
            "1/100 and 108/374 => train_loss: 0.7060 and train_metric: 0.5095\n",
            "1/100 and 109/374 => train_loss: 0.6669 and train_metric: 0.5818\n",
            "1/100 and 110/374 => train_loss: 0.6761 and train_metric: 0.5636\n",
            "1/100 and 111/374 => train_loss: 0.7431 and train_metric: 0.4393\n",
            "1/100 and 112/374 => train_loss: 0.6975 and train_metric: 0.5248\n",
            "1/100 and 113/374 => train_loss: 0.6556 and train_metric: 0.5969\n",
            "1/100 and 114/374 => train_loss: 0.6472 and train_metric: 0.6117\n",
            "1/100 and 115/374 => train_loss: 0.7114 and train_metric: 0.4987\n",
            "1/100 and 116/374 => train_loss: 0.7197 and train_metric: 0.4830\n",
            "1/100 and 117/374 => train_loss: 0.7355 and train_metric: 0.4524\n",
            "1/100 and 118/374 => train_loss: 0.6959 and train_metric: 0.5273\n",
            "1/100 and 119/374 => train_loss: 0.6524 and train_metric: 0.6058\n",
            "1/100 and 120/374 => train_loss: 0.6943 and train_metric: 0.5290\n",
            "1/100 and 121/374 => train_loss: 0.6883 and train_metric: 0.5424\n",
            "1/100 and 122/374 => train_loss: 0.6986 and train_metric: 0.5210\n",
            "1/100 and 123/374 => train_loss: 0.7111 and train_metric: 0.4996\n",
            "1/100 and 124/374 => train_loss: 0.6577 and train_metric: 0.5930\n",
            "1/100 and 125/374 => train_loss: 0.6619 and train_metric: 0.5867\n",
            "1/100 and 126/374 => train_loss: 0.7269 and train_metric: 0.4697\n",
            "1/100 and 127/374 => train_loss: 0.6719 and train_metric: 0.5712\n",
            "1/100 and 128/374 => train_loss: 0.6631 and train_metric: 0.5870\n",
            "1/100 and 129/374 => train_loss: 0.7291 and train_metric: 0.4672\n",
            "1/100 and 130/374 => train_loss: 0.6665 and train_metric: 0.5780\n",
            "1/100 and 131/374 => train_loss: 0.6701 and train_metric: 0.5746\n",
            "1/100 and 132/374 => train_loss: 0.7227 and train_metric: 0.4791\n",
            "1/100 and 133/374 => train_loss: 0.6623 and train_metric: 0.5883\n",
            "1/100 and 134/374 => train_loss: 0.6391 and train_metric: 0.6288\n",
            "1/100 and 135/374 => train_loss: 0.6909 and train_metric: 0.5332\n",
            "1/100 and 136/374 => train_loss: 0.7084 and train_metric: 0.5059\n",
            "1/100 and 137/374 => train_loss: 0.6663 and train_metric: 0.5827\n",
            "1/100 and 138/374 => train_loss: 0.7209 and train_metric: 0.4811\n",
            "1/100 and 139/374 => train_loss: 0.6914 and train_metric: 0.5345\n",
            "1/100 and 140/374 => train_loss: 0.6464 and train_metric: 0.6143\n",
            "1/100 and 141/374 => train_loss: 0.6963 and train_metric: 0.5249\n",
            "1/100 and 142/374 => train_loss: 0.6912 and train_metric: 0.5368\n",
            "1/100 and 143/374 => train_loss: 0.6447 and train_metric: 0.6165\n",
            "1/100 and 144/374 => train_loss: 0.7246 and train_metric: 0.4747\n",
            "1/100 and 145/374 => train_loss: 0.6897 and train_metric: 0.5371\n",
            "1/100 and 146/374 => train_loss: 0.6464 and train_metric: 0.6150\n",
            "1/100 and 147/374 => train_loss: 0.6564 and train_metric: 0.5973\n",
            "1/100 and 148/374 => train_loss: 0.7255 and train_metric: 0.4726\n",
            "1/100 and 149/374 => train_loss: 0.7162 and train_metric: 0.4915\n",
            "1/100 and 150/374 => train_loss: 0.7207 and train_metric: 0.4821\n",
            "1/100 and 151/374 => train_loss: 0.6955 and train_metric: 0.5283\n",
            "1/100 and 152/374 => train_loss: 0.7062 and train_metric: 0.5058\n",
            "1/100 and 153/374 => train_loss: 0.7320 and train_metric: 0.4606\n",
            "1/100 and 154/374 => train_loss: 0.7135 and train_metric: 0.4960\n",
            "1/100 and 155/374 => train_loss: 0.6906 and train_metric: 0.5410\n",
            "1/100 and 156/374 => train_loss: 0.6584 and train_metric: 0.5929\n",
            "1/100 and 157/374 => train_loss: 0.6734 and train_metric: 0.5694\n",
            "1/100 and 158/374 => train_loss: 0.7417 and train_metric: 0.4414\n",
            "1/100 and 159/374 => train_loss: 0.6968 and train_metric: 0.5253\n",
            "1/100 and 160/374 => train_loss: 0.6463 and train_metric: 0.6169\n",
            "1/100 and 161/374 => train_loss: 0.7047 and train_metric: 0.5084\n",
            "1/100 and 162/374 => train_loss: 0.7052 and train_metric: 0.5104\n",
            "1/100 and 163/374 => train_loss: 0.6564 and train_metric: 0.5985\n",
            "1/100 and 164/374 => train_loss: 0.6920 and train_metric: 0.5340\n",
            "1/100 and 165/374 => train_loss: 0.7381 and train_metric: 0.4479\n",
            "1/100 and 166/374 => train_loss: 0.7066 and train_metric: 0.5088\n",
            "1/100 and 167/374 => train_loss: 0.6621 and train_metric: 0.5882\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}